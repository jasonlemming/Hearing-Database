# Instructions: Add these lines to cli.py after the crs-content command group (around line 1076)

# First, add these imports at the top of cli.py (around line 37):
# from brookings_ingester.ingesters import BrookingsIngester
# from brookings_ingester.models import init_database, get_session, Document, Source, IngestionLog

# Then add this entire command group before the "# Helper functions" section (around line 1078):

@cli.group(name='brookings')
def brookings():
    """Brookings Institution content management operations"""
    pass


@brookings.command()
def init():
    """Initialize Brookings database and seed sources"""
    logger = get_logger(__name__)

    try:
        from brookings_ingester.init_db import main as init_main
        result = init_main()

        if result == 0:
            logger.info("Brookings database initialized successfully")
        else:
            logger.error("Brookings database initialization failed")
            sys.exit(1)

    except Exception as e:
        logger.error(f"Initialization failed: {e}")
        sys.exit(1)


@brookings.command()
@click.option('--limit', default=None, type=int, help='Limit number of documents to ingest')
@click.option('--skip-existing', is_flag=True, default=True, help='Skip documents that already exist')
@click.option('--method', type=click.Choice(['api', 'sitemap', 'both']), default='api',
              help='Discovery method: api (WordPress), sitemap, or both')
@click.option('--since-date', default='2025-01-01', help='Only ingest documents published on/after this date (YYYY-MM-DD)')
def backfill(limit, skip_existing, method, since_date):
    """Initial backfill of Brookings content"""
    logger = get_logger(__name__)

    try:
        from brookings_ingester.ingesters import BrookingsIngester

        logger.info(f"Starting Brookings backfill (method={method}, since={since_date})")
        ingester = BrookingsIngester()

        result = ingester.run_ingestion(
            limit=limit,
            skip_existing=skip_existing,
            run_type='backfill',
            method=method,
            since_date=since_date
        )

        if result['success']:
            logger.info("Backfill completed successfully")
        else:
            logger.error(f"Backfill failed: {result.get('error', 'Unknown error')}")
            sys.exit(1)

    except Exception as e:
        logger.error(f"Backfill failed: {e}")
        sys.exit(1)


@brookings.command()
@click.option('--days', default=30, help='Update documents modified in last N days')
@click.option('--method', type=click.Choice(['api', 'sitemap', 'both']), default='api')
def update(days, method):
    """Update Brookings content for recently modified documents"""
    logger = get_logger(__name__)

    try:
        from brookings_ingester.ingesters import BrookingsIngester
        from datetime import datetime, timedelta

        since_date = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')
        logger.info(f"Updating Brookings content modified since {since_date}")

        ingester = BrookingsIngester()
        result = ingester.run_ingestion(
            limit=None,
            skip_existing=False,
            run_type='update',
            method=method,
            since_date=since_date
        )

        if result['success']:
            logger.info("Update completed successfully")
        else:
            logger.error(f"Update failed: {result.get('error')}")
            sys.exit(1)

    except Exception as e:
        logger.error(f"Update failed: {e}")
        sys.exit(1)


@brookings.command()
@click.option('--detailed', is_flag=True, help='Show detailed statistics')
def stats(detailed):
    """Show Brookings content statistics"""
    logger = get_logger(__name__)

    try:
        from brookings_ingester.models import get_session, Document, Source, IngestionLog
        from sqlalchemy import func

        session = get_session()
        brookings = session.query(Source).filter_by(source_code='BROOKINGS').first()

        if not brookings:
            logger.error("Brookings source not found. Run: python cli.py brookings init")
            sys.exit(1)

        total_docs = session.query(Document).filter_by(source_id=brookings.source_id).count()
        total_words = session.query(func.sum(Document.word_count)).filter_by(source_id=brookings.source_id).scalar() or 0
        with_pdfs = session.query(Document).filter(
            Document.source_id == brookings.source_id,
            Document.pdf_url.isnot(None)
        ).count()

        click.echo("\n" + "=" * 70)
        click.echo("Brookings Content Statistics")
        click.echo("=" * 70)
        click.echo(f"Total documents:       {total_docs:>10,}")
        click.echo(f"Total words:           {total_words:>10,}")
        click.echo(f"Documents with PDFs:   {with_pdfs:>10,}")
        click.echo("=" * 70 + "\n")

        session.close()

    except Exception as e:
        logger.error(f"Stats failed: {e}")
        sys.exit(1)


@brookings.command()
@click.option('--url', required=True, help='Brookings document URL to ingest')
def ingest_url(url):
    """Ingest a single Brookings document by URL"""
    logger = get_logger(__name__)

    try:
        from brookings_ingester.ingesters import BrookingsIngester

        ingester = BrookingsIngester()
        doc_meta = {'document_identifier': ingester._extract_slug(url), 'url': url}

        fetched = ingester.fetch(doc_meta)
        if not fetched:
            logger.error("Failed to fetch content")
            sys.exit(1)

        parsed = ingester.parse(doc_meta, fetched)
        if not parsed:
            logger.error("Failed to parse content")
            sys.exit(1)

        document_id = ingester.store(parsed)
        if not document_id:
            logger.error("Failed to store document")
            sys.exit(1)

        logger.info(f"âœ“ Successfully ingested document (ID: {document_id})")

    except Exception as e:
        logger.error(f"Ingestion failed: {e}")
        sys.exit(1)
