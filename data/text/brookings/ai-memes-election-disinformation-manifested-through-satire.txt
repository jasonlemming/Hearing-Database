As the United States prepares for the upcoming November election, misinformation and disinformation have spread through memes.

Memes are any idea, expression, or opinion that uses text, visual imagery (e. g., a photo, video, or gif file) with or without sound, which can be copied and shared online.

For researchers, they are co-constructions that have meaning primarily in humor, which can be shared by multiple users, and in the case of the internet, across various platforms.

The convenient availability of commercial artificial intelligence (AI) tools has also contributed to the existing meme economy.

Software like X’s AI chatbot called Grok can quickly generate such images, especially with its ability to use famous peoples’ likenesses, copyrighted material, violent content, or pornographic image generation.

The reality is that AI-generated memes have been inserted into the political conversation.

These altered images often seem harmless to voters, particularly because they are sometimes shared by people they trust in their personal and professional networks.

It can be difficult for policymakers or content moderators to definitively assess their impact because the humor or profile of memes makes them appear innocuous.

In the current policy environment where content moderation and domestic AI policy are still evolving, those who develop and disseminate memes can potentially influence voter information about candidate issues, character, and other relevant election information without the usual guardrails that either regulate speech in the U.S. or trigger attention based on the manipulation of political content.

[H2]What are memes?

Tugging on the emotions of voters is a critical part of influencing them to act.

Memes present unique opportunities because they can disseminate information and foster a sense of community through humor and other apolitical ways.

Examples of the persuasive power of memes have appeared in efforts to spread political messaging, alter the stock market, or even influence the way the public thinks about war.

The current campaign efforts on both sides are also no exception.

The Trump campaign and his allies have created an assortment of AI-generated memes to uplift the former president, which have been shared on the social media platform Xand Truth Social.

There has also been a share of visualizations that have ridiculed the other side, including one of Vice President Kamala Harris leading a communist rally, while another showed many Taylor Swift fans endorsing his campaign.

Trump supporters like Musk have even reposted an AI-altered, “ parody ” video of Harris calling herself a “deep state puppet” and “the ultimate diversity hire.”
On the other side, Vice President Harris’ campaign and allies have generated their own share of memes.

During the 2024 Democratic National Convention, the highest number of content creators and online influencers ever were in attendance to capture these and other messages for attendees and viewers.

Throughout the event, robust online content was created, including the dissemination of memes to capture emotional responses to the various activities and speakers.

Doug Emhoff, the second gentlemen, was often the subject of memes as he openly conveyed his support for his wife, Kamala Harris.

Tim Walz’s son, Gus, also became a viral meme as he mouthed his admiration for his father during the acceptance speech.

The Harris campaign and allies have been equally culpable in their use of satirical tools.

Her team has also been accused of falsely captioning AI-generated videos and memes of the former president.

Through their use of clips from a Trump rally in North Carolina, the Harris social media account played up the theme that the former president was “lost and confused” in his suggestion that he was in another state—a point that was later fact-checked and clarified by the Harris team.

Probably the most viral memes being shared by both parties and their allies have been those AI-generated memes of cats on social media platforms, which tout the conspiracy theory and disinformation reference by Trump regarding Haitian immigrants eating pets in Springfield, Ohio—some of which were posted by the former president himself.

As these visualizations continue to become a part of the political landscape, memes will increasingly feed into misinformation and disinformation efforts, and cloak facts in humor and satire to elicit more emotional responses from voters.

Due to congressional inaction on copyright protections for the data training large language models (LLMs) or more stringent legislation to curb the flow of false information, memes can flourish and, under current election laws, be perceived to be harmless in nature.

[H2]Memes are also not necessarily deepfakes

Congress has also made it clear how they categorize memes when it comes to election and other voter interference.

Pending legislation, including the DEEPFAKES Accountability Act, create carve outs for memes, humor, satire, parody, and other commentary as a justification of an individual’s freedom of expression.

However, the task of deciphering what is parody and what is deceptive can be very challenging.

Despite the deceptive posts by Trump and Musk, for example, the label of satire provides some immunity from liability.

Such posts also receive additional protections under Section 230, which shields online platforms that disseminate the information from any liability or association—even if vile or offensive.

Memes also can provoke “rage-baiting,”  which refers to using online content to elicit strong negative emotional reactions from users.

However, the significant gaps in policy make their dissemination possible and plausible.

An examination of the handling of memes in a global context makes the case for stronger guardrails and increased community awareness.

Globally, memes have been perceived as fueling extremist behavior.

In 2024, a memo from the Netherland’s National Coordinator for Counterterrorism and Security (NCCS) considered memes to be an “online weapon,” suggesting that the lack of strong content moderation on online platforms has made it easier for memes to thrive and nest themselves in mainstream messaging that disguise their goal of radicalizing unsuspecting online users.

In their new book “Lies That Kill,” co-authors Darrell West and Elaine Kamarck point to these and other examples that persuade not just voters, but other everyday people, to consume false information at rapid speeds.

[H2]Memes are the next form of political influence

Misinformation and disinformation will continue to be a focus leading up to the November election.

While the time has run out for any meaningful legislation to counter deepfakes prior to this election cycle, AI-generated memes are something that policymakers, and especially campaigns, need to monitor.

Because of their ability to cloak deeply hateful and vitriolic messages into humorous and satirical images, they have been downplayed in the flow of political rhetoric.

Given this, Congress should reconsider the carveouts from pending legislation to quell deepfakes, especially in their use of copyrighted materials and their role in rapidly spreading disinformation.

Such loose creation and dissemination of memes should also encourage Congress and other lawmakers to consider some real investments in AI literacy for everyday people to understand the consequences of what they share online.

In the meantime, campaigns need to be on the lookout for memes that are harmful or that could potentially lead to violence.

The Brookings Institution is committed to quality, independence, and impact.

We are supported by a diverse array of funders.

In line with our values and policies, each Brookings publication represents the sole views of its author(s).